{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Code_Step4.ipynb","provenance":[{"file_id":"1tczZzIlC60B80eDBj6L3RqXg397KKtEb","timestamp":1609564725301}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ac1d9b6db8164fe68f0e301c0dcb899f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cc0f8ed357874fce879616c1b3800c85","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_910c437dd2844ea78f4fa04f5fb41cc0","IPY_MODEL_b20281d4ed1b40e9a30a95a64c8fa834"]}},"cc0f8ed357874fce879616c1b3800c85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"910c437dd2844ea78f4fa04f5fb41cc0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_76cb547156764862a64f730a4842bb7d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_11b65279f2374d51843fb2b96c279b05"}},"b20281d4ed1b40e9a30a95a64c8fa834":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_45becba53e4a47e39925d97a3d7eed28","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9920512/? [00:20&lt;00:00, 31352435.61it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7a3c343c7127467baa63634b72a17866"}},"76cb547156764862a64f730a4842bb7d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"11b65279f2374d51843fb2b96c279b05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"45becba53e4a47e39925d97a3d7eed28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7a3c343c7127467baa63634b72a17866":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"05a4dd7970574a1c91f5b4b68a4ab6bd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f1db7db629e04f5996969b81399c1983","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f2c2781519504498b631d68bbde5522c","IPY_MODEL_787d636b7826454c83d879d83e990022"]}},"f1db7db629e04f5996969b81399c1983":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f2c2781519504498b631d68bbde5522c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b422c321806641e1b88469cab3fba6d3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f5f8a683ad8f4215b4f551b24ccaf174"}},"787d636b7826454c83d879d83e990022":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_58d90a4a42cb4af2b3f683c6b8dcee68","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 32768/? [00:00&lt;00:00, 342050.46it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_76fb5e4d5d454aee9dba4cb744349ef3"}},"b422c321806641e1b88469cab3fba6d3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f5f8a683ad8f4215b4f551b24ccaf174":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"58d90a4a42cb4af2b3f683c6b8dcee68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"76fb5e4d5d454aee9dba4cb744349ef3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b42a4a04e7554f1dae731bfb98103b02":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_90394013245c4519b2955f5b39e7e0fb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_21983d14e96d4bcfbdc509c26de865c0","IPY_MODEL_bfb6390e15084a0a8b5af0a719bbe522"]}},"90394013245c4519b2955f5b39e7e0fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"21983d14e96d4bcfbdc509c26de865c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_36f7c92f575c46e5a2d54a5cacd8a1fb","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_30a0db2ced46472b9573332e1dfc463e"}},"bfb6390e15084a0a8b5af0a719bbe522":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_eee2f74f41474767b8a18f5e47139dd7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1654784/? [00:19&lt;00:00, 138910.29it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e3c847155a4f433eb15a79b37d092dfb"}},"36f7c92f575c46e5a2d54a5cacd8a1fb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"30a0db2ced46472b9573332e1dfc463e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eee2f74f41474767b8a18f5e47139dd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e3c847155a4f433eb15a79b37d092dfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d192de1a591e4e30b32e6e7b478fa06c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7a902146a5534938893fd092537532d0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9506e19b41584dc89efe75befb0395b9","IPY_MODEL_1cc0d9a6a22c4a0b94014c70f11b1ea6"]}},"7a902146a5534938893fd092537532d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9506e19b41584dc89efe75befb0395b9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bfc5c72ee4f24362a10c76785a470b6b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4ab6c3ea8b904651b2a34c7298795e82"}},"1cc0d9a6a22c4a0b94014c70f11b1ea6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_957bc93d3b9f42ebb755c5f544462f99","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 8192/? [00:00&lt;00:00, 27039.69it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f141d55f2d224b398a3169527ee65b2d"}},"bfc5c72ee4f24362a10c76785a470b6b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4ab6c3ea8b904651b2a34c7298795e82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"957bc93d3b9f42ebb755c5f544462f99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f141d55f2d224b398a3169527ee65b2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"d-x4JpzKBgRe"},"source":["##    Target\r\n","1.   Reduce the model size under 8K by reducing max channel size from 16 to 14\r\n","2.   Remove the Convolution layer#8 since we may not need it\r\n","3.   Increase the learning rate to 0.1 and use a multi step scheduler to X0.1 after iteration #10, 12\r\n","\r\n","##    Results:  \r\n","\r\n","1.   Parameters: 7098\r\n","2.   Best Train Accuracy: 99.35\r\n","3.   Best Test Accuracy: 99.48\r\n","\r\n","##    Analysis\r\n","\r\n","1.   We are there!\r\n"," "]},{"cell_type":"markdown","metadata":{"id":"aO-7t1Y7-hV4"},"source":["# Import Libraries"]},{"cell_type":"code","metadata":{"id":"8kH16rnZ7wt_","executionInfo":{"status":"ok","timestamp":1609622850613,"user_tz":300,"elapsed":3958,"user":{"displayName":"Tapas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgC1NIm8gUIIKsIv65tRPRFEAON1SFWqEmS8bcuBw=s64","userId":"10951166466092708436"}}},"source":["from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ky3f_Odl-7um"},"source":["## Data Transformations\n","\n","We first start with defining our data transformations. We need to think what our data is and how can we augment it to correct represent images which it might not see otherwise. \n"]},{"cell_type":"code","metadata":{"id":"YtssFUKb-jqx","executionInfo":{"status":"ok","timestamp":1609622850615,"user_tz":300,"elapsed":3953,"user":{"displayName":"Tapas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgC1NIm8gUIIKsIv65tRPRFEAON1SFWqEmS8bcuBw=s64","userId":"10951166466092708436"}}},"source":["# Train Phase transformations\n","train_transforms = transforms.Compose([\n","                                       #transforms.Resize((24, 24)),\n","                                       #transforms.CenterCrop(24),\n","                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n","                                       transforms.RandomRotation((-5.0, 5.0), fill=(1,)),                                       \n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n","                                       # Note the difference between (0.1307) and (0.1307,)\n","                                       ])\n","\n","# Test Phase transformations\n","test_transforms = transforms.Compose([\n","                                      #transforms.Resize((24, 24)),\n","                                      #transforms.CenterCrop(24), \n","                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n","                                       transforms.ToTensor(),                                      \n","                                       transforms.Normalize((0.1307,), (0.3081,))\n","                                       ])\n"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oQciFYo2B1mO"},"source":["# Dataset and Creating Train/Test Split"]},{"cell_type":"code","metadata":{"id":"_4A84rlfDA23","colab":{"base_uri":"https://localhost:8080/","height":404,"referenced_widgets":["ac1d9b6db8164fe68f0e301c0dcb899f","cc0f8ed357874fce879616c1b3800c85","910c437dd2844ea78f4fa04f5fb41cc0","b20281d4ed1b40e9a30a95a64c8fa834","76cb547156764862a64f730a4842bb7d","11b65279f2374d51843fb2b96c279b05","45becba53e4a47e39925d97a3d7eed28","7a3c343c7127467baa63634b72a17866","05a4dd7970574a1c91f5b4b68a4ab6bd","f1db7db629e04f5996969b81399c1983","f2c2781519504498b631d68bbde5522c","787d636b7826454c83d879d83e990022","b422c321806641e1b88469cab3fba6d3","f5f8a683ad8f4215b4f551b24ccaf174","58d90a4a42cb4af2b3f683c6b8dcee68","76fb5e4d5d454aee9dba4cb744349ef3","b42a4a04e7554f1dae731bfb98103b02","90394013245c4519b2955f5b39e7e0fb","21983d14e96d4bcfbdc509c26de865c0","bfb6390e15084a0a8b5af0a719bbe522","36f7c92f575c46e5a2d54a5cacd8a1fb","30a0db2ced46472b9573332e1dfc463e","eee2f74f41474767b8a18f5e47139dd7","e3c847155a4f433eb15a79b37d092dfb","d192de1a591e4e30b32e6e7b478fa06c","7a902146a5534938893fd092537532d0","9506e19b41584dc89efe75befb0395b9","1cc0d9a6a22c4a0b94014c70f11b1ea6","bfc5c72ee4f24362a10c76785a470b6b","4ab6c3ea8b904651b2a34c7298795e82","957bc93d3b9f42ebb755c5f544462f99","f141d55f2d224b398a3169527ee65b2d"]},"executionInfo":{"status":"ok","timestamp":1609622851667,"user_tz":300,"elapsed":4992,"user":{"displayName":"Tapas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgC1NIm8gUIIKsIv65tRPRFEAON1SFWqEmS8bcuBw=s64","userId":"10951166466092708436"}},"outputId":"b4a8d6b0-a590-4085-95ed-2e5db22e544d"},"source":["train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\n","test = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac1d9b6db8164fe68f0e301c0dcb899f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"05a4dd7970574a1c91f5b4b68a4ab6bd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b42a4a04e7554f1dae731bfb98103b02","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d192de1a591e4e30b32e6e7b478fa06c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","Processing...\n","Done!\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"qgldp_3-Dn0c"},"source":["# Dataloader Arguments & Test/Train Dataloaders\n"]},{"cell_type":"code","metadata":{"id":"C8OLDR79DrHG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609622852014,"user_tz":300,"elapsed":5332,"user":{"displayName":"Tapas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgC1NIm8gUIIKsIv65tRPRFEAON1SFWqEmS8bcuBw=s64","userId":"10951166466092708436"}},"outputId":"2166dc26-8b4b-4248-8008-235fb53164cd"},"source":["SEED = 1\n","\n","# CUDA?\n","cuda = torch.cuda.is_available()\n","print(\"CUDA Available?\", cuda)\n","\n","# For reproducibility\n","torch.manual_seed(SEED)\n","\n","if cuda:\n","    torch.cuda.manual_seed(SEED)\n","\n","# dataloader arguments - something you'll fetch these from cmdprmt\n","dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n","\n","# train dataloader\n","train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n","\n","# test dataloader\n","test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["CUDA Available? True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ubQL3H6RJL3h"},"source":["# The model\n","Let's start with the model we first saw"]},{"cell_type":"code","metadata":{"id":"7FXQlB9kH1ov","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609622852019,"user_tz":300,"elapsed":5328,"user":{"displayName":"Tapas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgC1NIm8gUIIKsIv65tRPRFEAON1SFWqEmS8bcuBw=s64","userId":"10951166466092708436"}},"outputId":"e96ca24a-cee1-4fa2-9903-386af4a7899b"},"source":["import torch.nn.functional as F\n","dropout_value = 0.05\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        # Input Block\n","        self.convblock1 = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=14, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(14),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 26\n","\n","        # CONVOLUTION BLOCK 1\n","        self.convblock2 = nn.Sequential(\n","            nn.Conv2d(in_channels=14, out_channels=14, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(14),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 24\n","\n","        # TRANSITION BLOCK 1\n","        self.convblock3 = nn.Sequential(\n","            nn.Conv2d(in_channels=14, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n","        ) # output_size = 24\n","        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 12\n","\n","        # CONVOLUTION BLOCK 2\n","        self.convblock4 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=14, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),            \n","            nn.BatchNorm2d(14),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 10\n","        self.convblock5 = nn.Sequential(\n","            nn.Conv2d(in_channels=14, out_channels=14, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),            \n","            nn.BatchNorm2d(14),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 8\n","        self.convblock6 = nn.Sequential(\n","            nn.Conv2d(in_channels=14, out_channels=14, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),            \n","            nn.BatchNorm2d(14),\n","           nn.Dropout(dropout_value)\n","        ) # output_size = 6        \n","        \n","        # OUTPUT BLOCK\n","        self.gap = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=6)\n","        ) # output_size = 1\n","\n","        self.convblock7 = nn.Sequential(\n","            nn.Conv2d(in_channels=14, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),           \n","        ) \n","\n","\n","        self.dropout = nn.Dropout(dropout_value)\n","\n","    def forward(self, x):\n","        x = self.convblock1(x)\n","        x = self.convblock2(x)\n","        x = self.convblock3(x)\n","        x = self.pool1(x)\n","        x = self.convblock4(x)\n","        x = self.convblock5(x)\n","        x = self.convblock6(x)\n","        #x = self.convblock7(x)\n","        x = self.gap(x)        \n","        x = self.convblock7(x)\n","\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x, dim=-1)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"M3-vp8X9LCWo"},"source":["# Model Params\n","Can't emphasize on how important viewing Model Summary is. \n","Unfortunately, there is no in-built model visualizer, so we have to take external help"]},{"cell_type":"code","metadata":{"id":"5skB97zIJQQe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609622864854,"user_tz":300,"elapsed":18150,"user":{"displayName":"Tapas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgC1NIm8gUIIKsIv65tRPRFEAON1SFWqEmS8bcuBw=s64","userId":"10951166466092708436"}},"outputId":"7e42421a-e02f-433c-ebbb-04f26c490d03"},"source":["!pip install torchsummary\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","print(device)\n","model = Net().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n","cuda\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 14, 26, 26]             126\n","              ReLU-2           [-1, 14, 26, 26]               0\n","       BatchNorm2d-3           [-1, 14, 26, 26]              28\n","           Dropout-4           [-1, 14, 26, 26]               0\n","            Conv2d-5           [-1, 14, 24, 24]           1,764\n","              ReLU-6           [-1, 14, 24, 24]               0\n","       BatchNorm2d-7           [-1, 14, 24, 24]              28\n","           Dropout-8           [-1, 14, 24, 24]               0\n","            Conv2d-9           [-1, 10, 24, 24]             140\n","        MaxPool2d-10           [-1, 10, 12, 12]               0\n","           Conv2d-11           [-1, 14, 10, 10]           1,260\n","             ReLU-12           [-1, 14, 10, 10]               0\n","      BatchNorm2d-13           [-1, 14, 10, 10]              28\n","          Dropout-14           [-1, 14, 10, 10]               0\n","           Conv2d-15             [-1, 14, 8, 8]           1,764\n","             ReLU-16             [-1, 14, 8, 8]               0\n","      BatchNorm2d-17             [-1, 14, 8, 8]              28\n","          Dropout-18             [-1, 14, 8, 8]               0\n","           Conv2d-19             [-1, 14, 6, 6]           1,764\n","             ReLU-20             [-1, 14, 6, 6]               0\n","      BatchNorm2d-21             [-1, 14, 6, 6]              28\n","          Dropout-22             [-1, 14, 6, 6]               0\n","        AvgPool2d-23             [-1, 14, 1, 1]               0\n","           Conv2d-24             [-1, 10, 1, 1]             140\n","================================================================\n","Total params: 7,098\n","Trainable params: 7,098\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.68\n","Params size (MB): 0.03\n","Estimated Total Size (MB): 0.71\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1__x_SbrL7z3"},"source":["# Training and Testing\n","\n","All right, so we have 24M params, and that's too many, we know that. But the purpose of this notebook is to set things right for our future experiments. \n","\n","Looking at logs can be boring, so we'll introduce **tqdm** progressbar to get cooler logs. \n","\n","Let's write train and test functions"]},{"cell_type":"code","metadata":{"id":"fbkF2nN_LYIb","executionInfo":{"status":"ok","timestamp":1609622864857,"user_tz":300,"elapsed":18147,"user":{"displayName":"Tapas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgC1NIm8gUIIKsIv65tRPRFEAON1SFWqEmS8bcuBw=s64","userId":"10951166466092708436"}}},"source":["from tqdm import tqdm\n","\n","train_losses = []\n","test_losses = []\n","train_acc = []\n","test_acc = []\n","\n","def train(model, device, train_loader, optimizer, epoch):\n","  model.train()\n","  pbar = tqdm(train_loader)\n","  correct = 0\n","  processed = 0\n","  for batch_idx, (data, target) in enumerate(pbar):\n","    # get samples\n","    data, target = data.to(device), target.to(device)\n","\n","    # Init\n","    optimizer.zero_grad()\n","    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n","    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n","\n","    # Predict\n","    y_pred = model(data)\n","\n","    # Calculate loss\n","    loss = F.nll_loss(y_pred, target)\n","    train_losses.append(loss)\n","\n","    # Backpropagation\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Update pbar-tqdm\n","    \n","    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","    correct += pred.eq(target.view_as(pred)).sum().item()\n","    processed += len(data)\n","\n","    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n","    train_acc.append(100*correct/processed)\n","    tqdm._instances.clear()\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    test_losses.append(test_loss)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","    \n","    test_acc.append(100. * correct / len(test_loader.dataset))"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"aE5Le6FYHhc8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609623132733,"user_tz":300,"elapsed":286013,"user":{"displayName":"Tapas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgC1NIm8gUIIKsIv65tRPRFEAON1SFWqEmS8bcuBw=s64","userId":"10951166466092708436"}},"outputId":"cb79d334-45b6-4b6a-db71-c1aa8acdf5e0"},"source":["from torch.optim.lr_scheduler import MultiStepLR\n","\n","model =  Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n","scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[8,12], gamma=0.1)\n","\n","\n","EPOCHS = 15\n","for epoch in range(1,EPOCHS+1):\n","    print(\"EPOCH:\", epoch)\n","    train(model, device, train_loader, optimizer, epoch)\n","    scheduler.step()\n","    test(model, device, test_loader)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["EPOCH: 1\n"],"name":"stdout"},{"output_type":"stream","text":["Loss=0.098656065762043 Batch_id=468 Accuracy=93.28: 100%|██████████| 469/469 [00:16<00:00, 29.03it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0622, Accuracy: 9795/10000 (97.95%)\n","\n","EPOCH: 2\n"],"name":"stdout"},{"output_type":"stream","text":["Loss=0.008829875849187374 Batch_id=468 Accuracy=97.99: 100%|██████████| 469/469 [00:16<00:00, 28.97it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0373, Accuracy: 9888/10000 (98.88%)\n","\n","EPOCH: 3\n"],"name":"stdout"},{"output_type":"stream","text":["Loss=0.17137320339679718 Batch_id=468 Accuracy=98.38: 100%|██████████| 469/469 [00:16<00:00, 28.84it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0348, Accuracy: 9884/10000 (98.84%)\n","\n","EPOCH: 4\n"],"name":"stdout"},{"output_type":"stream","text":["Loss=0.05286327376961708 Batch_id=468 Accuracy=98.64: 100%|██████████| 469/469 [00:16<00:00, 28.49it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0304, Accuracy: 9908/10000 (99.08%)\n","\n","EPOCH: 5\n"],"name":"stdout"},{"output_type":"stream","text":["Loss=0.015299908816814423 Batch_id=468 Accuracy=98.77: 100%|██████████| 469/469 [00:16<00:00, 28.38it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0297, Accuracy: 9904/10000 (99.04%)\n","\n","EPOCH: 6\n"],"name":"stdout"},{"output_type":"stream","text":["Loss=0.04624950513243675 Batch_id=468 Accuracy=98.80: 100%|██████████| 469/469 [00:16<00:00, 29.02it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0287, Accuracy: 9906/10000 (99.06%)\n","\n","EPOCH: 7\n"],"name":"stdout"},{"output_type":"stream","text":["Loss=0.03557458519935608 Batch_id=468 Accuracy=98.81: 100%|██████████| 469/469 [00:16<00:00, 29.06it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0285, Accuracy: 9914/10000 (99.14%)\n","\n","EPOCH: 8\n"],"name":"stdout"},{"output_type":"stream","text":["Loss=0.07746928185224533 Batch_id=468 Accuracy=98.92: 100%|██████████| 469/469 [00:16<00:00, 28.88it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0245, Accuracy: 9923/10000 (99.23%)\n","\n","EPOCH: 9\n"],"name":"stdout"},{"output_type":"stream","text":["Loss=0.06307858973741531 Batch_id=468 Accuracy=99.19: 100%|██████████| 469/469 [00:16<00:00, 29.21it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0190, Accuracy: 9947/10000 (99.47%)\n","\n","EPOCH: 10\n"],"name":"stdout"},{"output_type":"stream","text":["Loss=0.0025440531317144632 Batch_id=468 Accuracy=99.30: 100%|██████████| 469/469 [00:15<00:00, 29.39it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0185, Accuracy: 9945/10000 (99.45%)\n","\n","EPOCH: 11\n"],"name":"stdout"},{"output_type":"stream","text":["Loss=0.004622295498847961 Batch_id=468 Accuracy=99.29: 100%|██████████| 469/469 [00:16<00:00, 29.24it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0185, Accuracy: 9941/10000 (99.41%)\n","\n","EPOCH: 12\n"],"name":"stdout"},{"output_type":"stream","text":["Loss=0.03249935060739517 Batch_id=468 Accuracy=99.29: 100%|██████████| 469/469 [00:16<00:00, 29.11it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0179, Accuracy: 9946/10000 (99.46%)\n","\n","EPOCH: 13\n"],"name":"stdout"},{"output_type":"stream","text":["Loss=0.029224485158920288 Batch_id=468 Accuracy=99.32: 100%|██████████| 469/469 [00:15<00:00, 29.62it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0182, Accuracy: 9944/10000 (99.44%)\n","\n","EPOCH: 14\n"],"name":"stdout"},{"output_type":"stream","text":["Loss=0.0018407575553283095 Batch_id=468 Accuracy=99.33: 100%|██████████| 469/469 [00:15<00:00, 29.53it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0178, Accuracy: 9947/10000 (99.47%)\n","\n","EPOCH: 15\n"],"name":"stdout"},{"output_type":"stream","text":["Loss=0.013724863529205322 Batch_id=468 Accuracy=99.35: 100%|██████████| 469/469 [00:15<00:00, 29.41it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0178, Accuracy: 9948/10000 (99.48%)\n","\n"],"name":"stdout"}]}]}