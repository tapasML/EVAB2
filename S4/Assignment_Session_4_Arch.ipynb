{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment_Session_5_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGpmrS1peESC"
      },
      "source": [
        "**Install required packages**\r\n",
        "\r\n",
        "select GPU as device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b2cb2d2-685e-4924-b0fe-6f872538ae08"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVRAYfJpemG4"
      },
      "source": [
        "**Define the Network**\r\n",
        "\r\n",
        "Since parameters size is retricted, we can not suddenly expand and reduce channels in a layer, as it hurts learning weights. \r\n",
        "Instead start small (10 channels) and increase uniformly in baby steps.\r\n",
        "\r\n",
        "Using padding in first two blocks, to preserve every pixel of information we got.\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "Block #1:\r\n",
        "\r\n",
        "[Conv-> ReLU-> BatchNorm] -> [Conv-> ReLU-> BatchNorm] -> MaxPool -> Dropout\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "Block #2:\r\n",
        "\r\n",
        "[Conv-> ReLU-> BatchNorm] -> [Conv-> ReLU-> BatchNorm] -> MaxPool -> Dropout\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "Block #3:\r\n",
        "\r\n",
        "[Conv-> GAP]\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "Block #4:\r\n",
        "\r\n",
        "[Flatten -> Log_SoftMax]\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Cx9q2QFgM7"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1,  10, 3, padding=1) #input:28X28X1, out:28X28X10,  kernel:3X3, RF: 3.\n",
        "        self.conv2 = nn.Conv2d(10, 10, 3, padding=1) #input:28X28X10, out:28X28X10, kernel:3X3, RF: 5.\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)              #input:28X28X10, out:14X14X10, kernel:2X2, RF: 10\n",
        "        self.conv3 = nn.Conv2d(10, 20, 3, padding=1) #input:14X14X10, out:14X14X20, kernel:3X3, RF: 12.\n",
        "        self.conv4 = nn.Conv2d(20, 20, 3, padding=1) #input:14X14X20, out:14X14X20, kernel:3X3, RF: 14.\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)              #input:14X14X20, out:7X7X20,   kernel:2X2, RF: 28\n",
        "        self.conv5 = nn.Conv2d(20, 30, 3, padding=0) #input:7X7X20, out:5X5X30,     kernel:3X3, RF: 30.\n",
        "        self.conv6 = nn.Conv2d(30, 10, 3)            #input:5X5X30, out:3X3X10,     kernel:3X3, RF: 32.        \n",
        "        self.avg_pool = nn.AvgPool2d(kernel_size=3, stride=3)#input:3X3X10, out:1X1X10, kernel:3X3\n",
        "\n",
        "        self.batchNorm_1 = nn.BatchNorm2d(10)\n",
        "        self.batchNorm_2 = nn.BatchNorm2d(10)\n",
        "        self.batchNorm_3 = nn.BatchNorm2d(20)\n",
        "        self.batchNorm_4 = nn.BatchNorm2d(20)\n",
        "        self.batchNorm_5 = nn.BatchNorm2d(30)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.10) #10% performs well as found by trial\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.batchNorm_2(F.relu(self.conv2(self.batchNorm_1(F.relu(self.conv1(x)))))))\n",
        "        x = self.dropout(x)\n",
        "        x = self.pool2(self.batchNorm_4(F.relu(self.conv4(self.batchNorm_3(F.relu(self.conv3(x)))))))\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv6(self.batchNorm_5(F.relu(self.conv5(x))))          \n",
        "        x = self.avg_pool(x) \n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmybhdUBjnX6"
      },
      "source": [
        "**Instatiate Network**\r\n",
        "\r\n",
        "Assign GPU to network model\r\n",
        "\r\n",
        "Print the model\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdydjYTZFyi3",
        "outputId": "739f7247-5f5c-4629-aaee-ffb8820ff123"
      },
      "source": [
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 10, 28, 28]             100\n",
            "       BatchNorm2d-2           [-1, 10, 28, 28]              20\n",
            "            Conv2d-3           [-1, 10, 28, 28]             910\n",
            "       BatchNorm2d-4           [-1, 10, 28, 28]              20\n",
            "         MaxPool2d-5           [-1, 10, 14, 14]               0\n",
            "           Dropout-6           [-1, 10, 14, 14]               0\n",
            "            Conv2d-7           [-1, 20, 14, 14]           1,820\n",
            "       BatchNorm2d-8           [-1, 20, 14, 14]              40\n",
            "            Conv2d-9           [-1, 20, 14, 14]           3,620\n",
            "      BatchNorm2d-10           [-1, 20, 14, 14]              40\n",
            "        MaxPool2d-11             [-1, 20, 7, 7]               0\n",
            "          Dropout-12             [-1, 20, 7, 7]               0\n",
            "           Conv2d-13             [-1, 30, 5, 5]           5,430\n",
            "      BatchNorm2d-14             [-1, 30, 5, 5]              60\n",
            "           Conv2d-15             [-1, 10, 3, 3]           2,710\n",
            "        AvgPool2d-16             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 14,770\n",
            "Trainable params: 14,770\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.42\n",
            "Params size (MB): 0.06\n",
            "Estimated Total Size (MB): 0.48\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU097_L6kQKV"
      },
      "source": [
        "**Load Train and Test data**\r\n",
        "\r\n",
        "set Block size.\r\n",
        "\r\n",
        "Since we are using BatchNormalization, we should not normalize the data data while loading\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "source": [
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor()\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFV0is8Gkpou"
      },
      "source": [
        "**Train and Test Network Flow**\r\n",
        "\r\n",
        "Print Logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')       \n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztq3YQ9Ok4L4"
      },
      "source": [
        "**Execute The Network**\r\n",
        "\r\n",
        "Using SGD with learning rate = 0.01 and momentum.\r\n",
        "\r\n",
        "Since majorority of learning is done by 10 epochs, after 10, reduce the learning rate (using a scheduler) so as to reduce overshooting of weights\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMWbLWO6FuHb",
        "outputId": "d7fda780-2a95-4c8b-cea7-8c9105cc3e37"
      },
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.1)\n",
        "for epoch in range(1, 20):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "    scheduler.step()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "loss=0.08064878731966019 batch_id=468: 100%|██████████| 469/469 [00:09<00:00, 52.08it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0469, Accuracy: 9854/10000 (98.54%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.026820292696356773 batch_id=468: 100%|██████████| 469/469 [00:08<00:00, 52.26it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0325, Accuracy: 9909/10000 (99.09%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.035896461457014084 batch_id=468: 100%|██████████| 469/469 [00:09<00:00, 51.90it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0294, Accuracy: 9908/10000 (99.08%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.01397956907749176 batch_id=468: 100%|██████████| 469/469 [00:09<00:00, 51.66it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0284, Accuracy: 9913/10000 (99.13%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.028817376121878624 batch_id=468: 100%|██████████| 469/469 [00:09<00:00, 51.85it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0260, Accuracy: 9919/10000 (99.19%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.047780293971300125 batch_id=468: 100%|██████████| 469/469 [00:09<00:00, 51.97it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0213, Accuracy: 9938/10000 (99.38%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.004779382608830929 batch_id=468: 100%|██████████| 469/469 [00:09<00:00, 51.72it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0229, Accuracy: 9925/10000 (99.25%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.021971330046653748 batch_id=468: 100%|██████████| 469/469 [00:09<00:00, 51.90it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0214, Accuracy: 9934/10000 (99.34%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.0035173564683645964 batch_id=468: 100%|██████████| 469/469 [00:09<00:00, 51.94it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0200, Accuracy: 9935/10000 (99.35%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.019832327961921692 batch_id=468: 100%|██████████| 469/469 [00:09<00:00, 51.88it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0206, Accuracy: 9935/10000 (99.35%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.012461082078516483 batch_id=468: 100%|██████████| 469/469 [00:09<00:00, 51.83it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0169, Accuracy: 9943/10000 (99.43%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.004952632822096348 batch_id=468: 100%|██████████| 469/469 [00:09<00:00, 51.69it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0165, Accuracy: 9945/10000 (99.45%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.002459848066791892 batch_id=468: 100%|██████████| 469/469 [00:09<00:00, 51.65it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0162, Accuracy: 9943/10000 (99.43%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.0032375932205468416 batch_id=468: 100%|██████████| 469/469 [00:09<00:00, 50.89it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0168, Accuracy: 9942/10000 (99.42%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.00777672091498971 batch_id=468: 100%|██████████| 469/469 [00:09<00:00, 51.32it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0162, Accuracy: 9947/10000 (99.47%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.038749802857637405 batch_id=468: 100%|██████████| 469/469 [00:09<00:00, 51.26it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0164, Accuracy: 9943/10000 (99.43%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.0074215536005795 batch_id=468: 100%|██████████| 469/469 [00:09<00:00, 51.17it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0164, Accuracy: 9942/10000 (99.42%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.044293541461229324 batch_id=468: 100%|██████████| 469/469 [00:09<00:00, 50.99it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0165, Accuracy: 9943/10000 (99.43%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.014885426498949528 batch_id=468: 100%|██████████| 469/469 [00:09<00:00, 50.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0168, Accuracy: 9943/10000 (99.43%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So5uk4EkHW6R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}